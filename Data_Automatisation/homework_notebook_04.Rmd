---
title: "automatization_notebook_04"
output:
  html_document:
    df_print: paged
date: "`r Sys.Date()`"
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(summarytools)
library(GGally)
library(RColorBrewer)
library(ggpubr)
library(reshape2)
library(pheatmap)
```

# Чтение данных

В вашем варианте нужно использовать датасет
healthcare-dataset-stroke-data.

```{r}
data = read_csv("./healthcare-dataset-stroke-data.csv")

head(data)
```

# Выведите общее описание данных

```{r}
summary(data)
```

```{r}
glimpse(data)
```

Видим следующую картину: \* Числовые колонки: age [похоже тут есть
аутлайеры], avg_glucose_level, bmi [bmi надо поправить] \* Бинарные
колонки (0 - False, 1 - True): hypertension, heart_disease,
ever_married, stroke \* Категориальные колонки: Work_type,
Residence_type, smoking_status, gender (вообще, часть из этих колонок
можно было бы перевести в бинарные, но, на мой взгляд, это сделало бы
интерпретацию этих колонок более тяжелой, поэтому лучше оставить их
строками)

Ищем в числовых колонках (с форматов doublefloat) N/A:

```{r}
data %>%
  select(where(is.numeric)) %>%
  summarise_all(function(x) sum(is.na(.)))
```

Видим, что в исходных числовых и бинарных колонках, нет N/A

Ищем N/A в категориальных(строковых) колонках:

```{r}
unique_values_each <- data %>%
  select(where(is.character)) %>%
  summarise_all(~ list(unique(.)))

print(unique_values_each %>% pull(gender))
print(unique_values_each %>% pull(ever_married))
print(unique_values_each %>% pull(smoking_status))
print(unique_values_each %>% pull(Residence_type))
print(unique_values_each %>% pull(work_type))
print(unique_values_each %>% pull(bmi))
```

Видим, что у нас есть "Unknown" и "N/A" значения в колонках `bmi` и
`smoking_status` =\> тогда к ним у нас будет пристальное внимание.

# Очистка данных

1)  Уберите переменные, в которых пропущенных значений больше 20% или
    уберите субъектов со слишком большим количеством пропущенных
    значений. Или совместите оба варианта. Напишите обоснование, почему
    вы выбрали тот или иной вариант

2)  Переименуйте переменные в человекочитаемый вид (что делать с
    пробелами в названиях?);

3)  В соответствии с описанием данных приведите переменные к нужному
    типу (numeric или factor);

4)  Отсортируйте данные по возрасту по убыванию;

5)  Сохраните в файл outliers.csv субъектов, которые являются выбросами
    (например, по правилу трёх сигм) — это необязательное задание со
    звёздочкой;

6)  Присвойте получившийся датасет переменной "cleaned_data".

## Выполнение

### Пункты 1-3 + 4

Начнём со 2) и 3) пункта, а потом будем N/A искать

Переимменуем колонки

```{r}
cleaned_data = data %>%
  rename(
    Id = id,
    Age = age,
    Gender = gender,
    Hypertension = hypertension,
    Heart_Disease = heart_disease,
    Ever_Married = ever_married,
    Work_Type = work_type,
    Residence_Type = Residence_type,
    Average_Glucose_Level = avg_glucose_level, 
    BMI = bmi,
    Smoking_Status = smoking_status,
    Stroke_Status = stroke
  )

cleaned_data
```

Приведем категориальные переменные к правильному виду + фиксим BMI

```{r}
# Фиксим BMI, тут N/A правильно обрабатываются
cleaned_data = cleaned_data %>%
     mutate(BMI = as.numeric(BMI))

# Также вспоминаем, что у нас в Smoking_Status есть "Unknown"
cleaned_data = cleaned_data %>%
  mutate(Smoking_Status = na_if(Smoking_Status, "Unknown"))

# Фиксим остальные категориальные переменные
cleaned_data = cleaned_data %>% 
  mutate(across(where(is.character), as.factor))

# Поправим Work_Type
cleaned_data = cleaned_data %>%
  mutate(Work_Type = recode(Work_Type,
                            "Private" = "Private_Sector",
                            "Self-employed" = "Freelancer",
                            "Govt_job" = "Government",
                            "children" = "Children",
                            "Never_worked" = "Never_worked"))

# Поправим Work_Type
cleaned_data = cleaned_data %>%
  mutate(Smoking_Status = recode(Smoking_Status,
                            "formerly smoked" = "Formely",
                            "never smoked" = "Never",
                            "smokes" = "Current",))

# Фиксим ever_married колонку
cleaned_data = cleaned_data %>% 
  mutate(Ever_Married = recode(Ever_Married,
                            "Yes" = 1,
                            "No" = 0)) %>%
  mutate(Ever_Married = as.numeric(Ever_Married))

head(cleaned_data)
```

А еще посмотрим, что у нас с возратом? Есть ли аутлайеры?

```{r}
# Смотрим на распределение возраста
cleaned_data %>%
     select(Age) %>% ggplot(aes(x = Age)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black")

cleaned_data %>% filter(Age <5) %>% head()

```

Видим, что "аутлайеры" у нас есть, но это дети, которые, видимо,
участвовали, в исследовании, так что все ок.

Теперь посмотрим N/A:

```{r}
# Смотрим NA в каждой из колонок
cleaned_data %>%
  summarise(across(everything(), ~ sum(is.na(.)), .names = "na_{.col}"))

```

Видим, что больше всего N/A у нас в колонке `Smoking_Status`. Давайте
посмотрим, что у нас в строках, где N/A по курению:

```{r}
cleaned_data %>%
  filter(is.na(Smoking_Status)) %>% summary()
```

```{r}
cleaned_data
```

Видим, что у нас много детей с неизвестным статусом курения.
Предположим, что дети все-таки не курят (в большинстве своём) и всем
детям проставим статус "never smoked":

```{r}
# Смотрим на распределение возраста
cleaned_data = cleaned_data %>%
  mutate(Smoking_Status = recode(Smoking_Status,
                            "Formely" = "1",
                            "Never" = "2",
                            "Current" = "3")) %>%
 mutate(Smoking_Status = as.factor(ifelse(Work_Type == "Children" & is.na(Smoking_Status), "Never", Smoking_Status))) %>%
 mutate(Smoking_Status = recode(Smoking_Status,
                           "1" = 'Formely',
                           "2" = 'Never',
                           "3" = 'Current'))
```

Теперь посмотрим N/A:

```{r}
# Смотрим NA в каждой из колонок
cleaned_data %>%
  summarise(across(everything(), ~ sum(is.na(.)), .names = "na_{.col}"))

```

Теперь во всех колонках N/A % \< 20%, убирать колонку Smoking_Status не
будем, т.к. это обычная проблема, что статус курения не фиксируется,
фиксируется плохо. Если что, в нашем анализе будем аккуратны конкретно с
этой колонкой

Сортируем

```{r}
cleaned_data <- cleaned_data %>%
  arrange(desc(Age))

cleaned_data
```

## Сколько осталось переменных?

```{r}
length(cleaned_data)
```

## Сколько осталось случаев?

```{r}

dim(cleaned_data)[1]

```

## Есть ли в данных идентичные строки?

```{r}

sum(duplicated(cleaned_data)) 

```

Нет идентичных строчек

## Сколько всего переменных с пропущенными значениями в данных и сколько пропущенных точек в каждой такой переменной?

```{r}
sum(is.na(cleaned_data))
```

# Описательные статистики

## Количественные переменные

1)  Рассчитайте для всех количественных переменных для каждой группы
    (stroke):

1.1) Количество значений;

1.2) Количество пропущенных значений;

1.3) Среднее;

1.4) Медиану;

1.5) Стандартное отклонение;

1.6) 25% квантиль и 75% квантиль;

1.7) Интерквартильный размах;

1.8) Минимум;

1.9) Максимум;

1.10) 95% ДИ для среднего - задание со звёздочкой.

```{r}

cleaned_data %>% 
  select(where(is.numeric) & (-c(Id, Hypertension, Heart_Disease, Stroke_Status, Ever_Married))) %>% 
  psych::describe(quant=c(.25,.75), IQR=T) %>% 
  mutate(CI_95_up = mean + 1.96 * se,
         CI_95_low = mean - 1.96 * se)

```

## Категориальные + Бинарные переменные

1)  Рассчитайте для всех категориальных переменных для каждой группы
    (stroke):

1.1) Абсолютное количество;

1.2) Относительное количество внутри группы;

1.3) 95% ДИ для доли внутри группы - задание со звёздочкой.

### Бинарные

Hypertension, Heart_Disease, Stroke_Status, Ever_Married

```{r}
categorical_columns <- c("Hypertension", "Heart_Disease", "Ever_Married")

cleaned_data %>%
  # Выбираем нужные колонки
  select(Hypertension, Heart_Disease, Stroke_Status, Ever_Married) %>%
  
  # Разбиваем
  pivot_longer(cols = all_of(categorical_columns), names_to = "Binary", values_to = "Value") %>%
  
  # Группируем по Stroke_Status, Binary и Value, и считаем количество
  group_by(Stroke_Status, Binary, Value) %>%
  summarise(count = n(), .groups = 'drop') %>%
  
  # Группируем по Stroke_Status и Binary, чтобы вычислить общее количество и относительные частоты
  group_by(Stroke_Status, Binary) %>%
  mutate(
    total = sum(count),                  # Общее количество внутри каждой группы Stroke_Status
    relative_count = count / total,      # Относительное количество внутри группы Stroke_Status
  ) %>% 
  
  # Снова меняем группировку на лету, чтобы все правильно посчитать
  ungroup() %>%
  group_by(Stroke_Status, Binary, Value) %>%
  mutate(CI_lower = prop.test(count, total, conf.level = 0.95)$conf.int[1],  # Нижняя граница 95% ДИ
    CI_upper = prop.test(count, total, conf.level = 0.95)$conf.int[2]   # Верхняя граница 95% ДИ
  ) %>%
  
  # Сортируем результат для удобства
  arrange(Stroke_Status, Binary, desc(count)) %>%
  
  # Сбрасываем группировку
  ungroup()
```

### Категориальные

```{r}
cleaned_data %>%
  # Выбираем нужные колонки
  select(where(is.factor), (Stroke_Status)) %>%
  
  # Группируем по уникальным комбинациям
  group_by(Stroke_Status) %>%
  
  # Разбиваем
  pivot_longer(cols = -Stroke_Status, names_to = "Category", values_to = "Value") %>%
  
  # Группируем по Stroke_Status, Binary и Value, и считаем количество
  group_by(Stroke_Status, Category, Value) %>%
  summarise(count = n(), .groups = 'drop') %>%
  
  # Группируем по Stroke_Status и Binary, чтобы вычислить общее количество и относительные частоты
  group_by(Stroke_Status, Category) %>%
  mutate(
    total = sum(count),                  # Общее количество внутри каждой группы Stroke_Status
    relative_count = count / total,      # Относительное количество внутри группы Stroke_Status
  ) %>% 
  
  # Снова меняем группировку на лету, чтобы все правильно посчитать
  ungroup() %>%
  group_by(Stroke_Status, Category, Value) %>%
  mutate(CI_lower = prop.test(count, total, conf.level = 0.95)$conf.int[1],  # Нижняя граница 95% ДИ
    CI_upper = prop.test(count, total, conf.level = 0.95)$conf.int[2]   # Верхняя граница 95% ДИ
  ) %>%
  
  # Сортируем результат для удобства
  arrange(Stroke_Status, Category, desc(count)) %>%
  
  # Сбрасываем группировку
  ungroup()

```

# Визуализация

## Количественные переменные

1)  Для каждой количественной переменной сделайте боксплоты по группам.
    Расположите их либо на отдельных рисунках, либо на одном, но
    читаемо;

2)  Наложите на боксплоты beeplots - задание со звёздочкой.

3)  Раскрасьте боксплоты с помощью библиотеки RColorBrewer.

```{r, fig.height=8}
display.brewer.all()
```

```{r}
numeric_col = c("Age", "BMI" ,"Average_Glucose_Level")

cleaned_data %>% select(all_of(numeric_col), (Stroke_Status)) %>%
  mutate(Stroke_Status = as.factor(Stroke_Status)) %>%
  pivot_longer(names_to = "Numeric_Column", 
               values_to = "Value", 
               cols = -Stroke_Status) %>% 
  ggplot(aes(x = Stroke_Status, y = Value, fill = Stroke_Status)) +
  geom_boxplot() +
  geom_jitter(shape=20, color='black', width=0.1) +
  scale_fill_manual(values = brewer.pal(n = 2, name = "Spectral")) +
  facet_wrap(~Numeric_Column) +
  theme_bw()

```

Да, конечно, надо было все-таки бинарные колонки в факторы перевести
(такие как Stroke_Status), но ничего

## Категориальные+Бинарные переменные

1)  Сделайте подходящие визуализации категориальных переменных.
    Обоснуйте, почему выбрали именно этот тип.

```{r}

theme_custom <- function(){
  theme_bw() %+replace%
  theme(
    axis.text = element_text(size = 18),
    axis.title.y = element_text(size = 20, angle=90),
    axis.title.x = element_text(size = 22),
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 25),
  )
}


binary_columns = c("Hypertension", "Heart_Disease", "Ever_Married")

data_for_graph = cleaned_data %>% select(all_of(binary_columns), (Stroke_Status)) %>%
  mutate(Stroke_Status = as.factor(Stroke_Status),
         Hypertension = as.factor(Stroke_Status),
         Heart_Disease = as.factor(Heart_Disease),
         Ever_Married = as.factor(Ever_Married))

data_for_graph %>%
  pivot_longer(names_to = "Binary_Column",
               values_to = "Value",
               cols = -Stroke_Status) %>%
  ggplot(aes(x = Stroke_Status, fill=Value)) +
  geom_bar(position = "fill") +
  scale_fill_manual(values = brewer.pal(n = 2, name = "Dark2")) +
  facet_wrap(~Binary_Column) +
  theme_custom() +
  labs(
    title = "Bar Chart for Binary Columns",
    x = "Stroke Status",
    y = "Count"
  )

```

```{r, fig.height=8, fig.width=8}
library(ggforce)

theme_custom <- function(){
  theme_bw() %+replace%
  theme(
    axis.text = element_text(size = 18),
    axis.title.y = element_text(size = 20, angle=90),
    axis.title.x = element_text(size = 22),
    legend.text = element_text(size = 18),
    legend.title = element_text(size = 25),
  )
}


data_for_graph = cleaned_data %>% select(where(is.factor), (Stroke_Status)) %>%
  mutate(Stroke_Status = as.factor(Stroke_Status))

data_for_graph %>%
  pivot_longer(names_to = "Categorical_Column",
               values_to = "Value",
               cols = -Stroke_Status) %>%
  ggplot(aes(x = Stroke_Status, fill = Value)) +
  geom_bar(position = "fill") +
  facet_wrap(~Categorical_Column) +
  theme_custom() +
  labs(
    title = "Bar Chart for Binary Columns",
    x = "Stroke Status",
    y = "Count"
  )
```

NB: пока не понял, как легенду разбить на 4 штуки.

Решил, что стоит построить бот-бар-плоты для всех колонок, так проще
всего поверхностно посмотреть на данные и заметить какие-то особенности.

# Статистические оценки

## Проверка на нормальность

1)  Оцените каждую переменную на соответствие нормальному распределению
    с помощью теста Шапиро-Уилка. Какие из переменных являются
    нормальными и как как вы это поняли?

```{r}

cleaned_data %>% select(where(is.numeric) & (-c(Id, Hypertension, Heart_Disease, Ever_Married))) %>%
  group_by(Stroke_Status) %>%
  summarize(across(everything(), 
                   ~ round(shapiro.test(.)$p.value, 3), .names = "p_value_{.col}"),)
            # across(everything(), 
            #        ~ round(shapiro.test(.)$statistic, 3), .names = "statistic_{.col}"))

```

Везде нули... Похоже тест решил, что нормальностью тут и не пахнет.

2)  Постройте для каждой количественной переменной QQ-плот. Отличаются
    ли выводы от теста Шапиро-Уилка? Какой метод вы бы предпочли и
    почему?

```{r, fig.height=6, fig.width=10}

# Список количественных переменных, исключая бинарные и идентификатор
quantitative_data <- cleaned_data %>%
  select(-c(Id, Hypertension, Heart_Disease, Ever_Married)) %>%
  select(where(is.numeric)) %>%
  pivot_longer(cols = -Stroke_Status, names_to = "Variable", values_to = "Value")

# Построение QQ-плотов для каждой количественной переменной
quantitative_data %>% ggplot(aes(sample=Value, group=Stroke_Status, color=Stroke_Status))+
  stat_qq() +
  stat_qq_line() +
  facet_wrap(~Variable, scales = "free_y") +
  labs(
    title = "QQ Plots for Quantitative Variables",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_custom()

```

По QQ-плотам видим, что в принципе для всех колонок у нас есть
достаточно сильные отклонения от нормальности, особенно на краях
распределений. Однако, я по моему мнению, Age и BMI, в целом,
более-менее нормально распределены (что логично и мы ожидаем от них
нормальности).

А вот Глюкоза достаточно сильно отличается от нормального распределения,
особенно в верхних квантилях.

Обсуждение результатов: Тест Шапиро-Уилка: Этот тест количественно
проверяет, соответствуют ли данные нормальному распределению. Однако при
больших выборках он может быть слишком чувствительным, показывая
значимые отклонения даже для малых отклонений от нормальности.

QQ-плот: Позволяет визуально оценить отклонения от нормального
распределения. Если данные нормально распределены, точки будут
располагаться вдоль прямой. Отклонения от прямой указывают на отклонения
от нормальности. Например, сильные изгибы указывают на наличие выбросов
или асимметричное распределение.

Выводы и предпочтение тест Шапиро-Уилка: Он полезен для небольших
выборок и дает объективное p-значение для проверки нормальности. Однако
он может быть чувствителен к мелким отклонениям при больших выборках.

QQ-плот: Этот метод предпочтительнее при больших выборках или когда
важна визуальная оценка нормальности. Он позволяет наглядно увидеть, где
и насколько данные отклоняются от нормальности, что не всегда очевидно
из p-значения теста.

3)  Ниже напишите, какие ещё методы проверки на нормальность вы знаете и
    какие у них есть ограничения. Сразу вспоминается метод
    Колмогорова-Смирнова, но насколько знаю, у него не очень большая
    мощность. Порыскав в интернете нашел ещё, что есть куча модификаций
    К-С, улучшающих мощность и, например, не требующих подбора
    параметров исходных. Но, думаю, что глобальную проблему мощности К-С
    эти тесты не решают.

Есть ещё специфичные тесты оценки асимметриии и эксцесса. Эти параметры
должны быть около-нулевыми для нормального распределения. Пр. Тест
Харке-Бера. Но этому тесту нужна хорошая-большая выборка.

# Что не успелось

## Сравнение групп

1)  Сравните группы (переменная **stroke**) по каждой переменной (как
    количественной, так и категориальной). Для каждой переменной
    выберите нужный критерий и кратко обоснуйте его выбор в
    комментариях.

```{r}

```

## Далее идут **необязательные** дополнительные задания, которые могут принести вам дополнительные баллы в том числе в случае ошибок в предыдущих

### Корреляционный анализ

1)  Создайте корреляционную матрицу с визуализацией и поправкой на
    множественные сравнения. Объясните, когда лучше использовать
    корреляционные матрицы и в чём минусы и плюсы корреляционных
    исследований.

```{r}



```

### Моделирование

1)  Постройте регрессионную модель для переменной **stroke**. Опишите
    процесс построения

```{r}



```
